{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load relavent libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "bikes_filepath = '../../data/bikes.csv'\n",
    "\n",
    "original_data = pd.read_csv(filepath_or_buffer=bikes_filepath, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Clean all the data from the data frame <b>original_data</b> using methods of your choice. Call the new cleaned data frame <b>clean_data</b>. Use the <b>.isna().sum()</b> methods to check your method has filled all missing data.\n",
    "\n",
    "\n",
    "Using two methods to fill in missing data as the first does not guarentee to fill all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing data with linear interpolation\n",
    "clean_data = original_data.interpolate(method='linear')\n",
    "\n",
    "# Fill remaining missing data with backfilling\n",
    "clean_data = clean_data.fillna(method=\"bfill\")\n",
    "\n",
    "clean_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "<p> Which of the three data types discussed: numerical, ordinal and categorical are the following examples? </p>\n",
    "\n",
    "<ul>\n",
    "  <li>Key Stages in school</li>\n",
    "  <li>Count of pupils</li>\n",
    "  <li>Colour of a pupils jumper</li>\n",
    "</ul>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct data types of the examples are:\n",
    "* Ordinal\n",
    "* Numerical\n",
    "* Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Using the method shown in this section, one-hot encode the <b>\"weather_code\"</b> feature from <b>clean_data</b> and store the new data frame with the new <b>\"weather_code\"</b> columns as <b>weather_encoded_data</b>. Include the original <b>\"weather_code\"</b> feature in order to compare the results.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create new data frame with just the weather_code attribute.\n",
    "weather_data = pd.DataFrame(clean_data[\"weather_code\"], columns=[\"weather_code\"])\n",
    "\n",
    "# Initialise the encoder\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "# Fit_transform the categorical data. It needs to be in an array to be transformed.\n",
    "weather_encoded_array = one_hot_encoder.fit_transform(weather_data[[\"weather_code\"]]).toarray()\n",
    "\n",
    "# Fetch the feature names for use in the column headers.\n",
    "column_names = one_hot_encoder.get_feature_names(['weather_code'])\n",
    "\n",
    "# Create a new data frame with the weather encoded data array.\n",
    "weather_encoded_data = pd.DataFrame(data=weather_encoded_array, columns=column_names)\n",
    "\n",
    "# Use the original names of the categories.\n",
    "weather_encoded_data[\"original_weather\"] = clean_data[\"weather_code\"]\n",
    "\n",
    "weather_encoded_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "For all the <i>numerical</i> features in <b>clean_data</b> use the <b><i>RobustScaler()</b></i> to create a new data frame with the scaled data. This scaler has the same syntax as the previous shown. Call this frame <b>scaled_data</b>. Be sure to check what your data looks like after it has been scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the **`pandas`** function **`.select_dtypes(include='number')`** to return only columns of a certain data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Initialise scaler\n",
    "rb_scaler = RobustScaler()\n",
    "\n",
    "# Select only numerical data and remove the target variable.\n",
    "numerical_data = clean_data.select_dtypes(include='number').drop(columns=[\"count\"])\n",
    "\n",
    "# Scale the features, produces an array.\n",
    "scaled_features_array = rb_scaler.fit_transform(numerical_data)\n",
    "\n",
    "# Put the scaled array into a data frame. \n",
    "scaled_data = pd.DataFrame(scaled_features_array, columns=numerical_data.columns)\n",
    "\n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "Using the <b>weather_encoded_data</b> frame from Exercise 4, plot a correlation map to see the relationship between different weather codes and the bike count. You will need to make sure <i>\"count\"</i> is in the data frame. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Attach the count attribute to the data frame.\n",
    "# This needs to be done so we can find the correlation between the features and count.\n",
    "weather_encoded_data[\"count\"] = clean_data[\"count\"]\n",
    "\n",
    "# Generate the correlation coefficients using the pandas method.\n",
    "correlation_matrix = weather_encoded_data.corr()\n",
    "\n",
    "# Plot the correlation matrix.\n",
    "correlation_matrix.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "\n",
    "Using the <b>weather_encoded_data</b> previously prepared find the <i>four</i> most important attributes in the data set using a <b><i>\"score_func=\"</b></i> argument not used in the example above. Store this as the data frame <b>best_four_data<b>.\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "\n",
    "# Set the number of attributes\n",
    "K = 4\n",
    "\n",
    "# Remove the target and pre-encoded attributes as they are not features.\n",
    "weather_encoded_data = weather_encoded_data.drop(columns=[\"count\", \"original_weather\"])\n",
    "\n",
    "# Initialise the selector.\n",
    "mutual_info_selector = SelectKBest(score_func=mutual_info_regression, k=K)\n",
    "\n",
    "# Fit the selector to the encoded weather data.\n",
    "mutual_info_selector.fit(X=weather_encoded_data, y=clean_data[\"count\"])\n",
    "\n",
    "# Find the chosen attributes with True/False values.\n",
    "columns_selected = mutual_info_selector.get_support()\n",
    "\n",
    "# Select the most important columns from the original frame.\n",
    "selected_cols = weather_encoded_data.columns[columns_selected]\n",
    "print(\"Top {} Columns are:\\n\\n\\t\".format(K), selected_cols)\n",
    "\n",
    "# Create a data frame of just the most important features.\n",
    "best_four_data = weather_encoded_data[selected_cols]\n",
    "print(columns_selected)\n",
    "best_four_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
